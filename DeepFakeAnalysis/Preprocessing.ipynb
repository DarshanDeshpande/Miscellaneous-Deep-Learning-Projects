{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz5tZVAen8_5",
        "colab_type": "code",
        "outputId": "8ebc8260-f158-47a7-c8f9-feaec59895c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        " %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2,os,io\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71YXj8sJuHuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "classes = ['REAL','FAKE']\n",
        "class_list,name_of_files = [], []\n",
        "\n",
        "with open(\"/content/drive/My Drive/DeepFakeFiles/train_data/metadata.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for video_id,info in data.items():\n",
        "        if info['label'] == 'FAKE':\n",
        "            class_list.append(1)\n",
        "        else:\n",
        "            class_list.append(0)\n",
        "        name_of_files.append(video_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voywE4nbuwsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "paths = glob.glob(\"/content/drive/My Drive/DeepFakeFiles/train_data/*.mp4\")\n",
        "print(len(paths))\n",
        "labels = []\n",
        "i=0\n",
        "for f in paths:\n",
        "  if os.path.basename(f) in name_of_files:\n",
        "    labels.append(class_list[name_of_files.index(os.path.basename(f))])\n",
        "print(labels,len(labels),\"\\n\",name_of_files)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELvCqLaSMQNS",
        "colab_type": "code",
        "outputId": "777cc9a1-7996-4a50-dc7c-775270f2cff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from random import shuffle\n",
        "c = list(zip(paths,labels))\n",
        "shuffle(c)\n",
        "paths,labels = zip(*c)\n",
        "print(paths)\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wk6GaUqMXvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_paths = paths[0:int(0.8*len(paths))]\n",
        "train_labels = labels[0:int(0.8*len(labels))]\n",
        "val_paths = paths[int(0.8*len(paths)):int(1*len(paths))]\n",
        "val_labels = labels[int(0.8*len(paths)):int(1*len(paths))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf7mx9u1MddC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_to_array(video,shape=(500,500),rescale=1/256.):\n",
        "    nbframe = 5\n",
        "    images = []\n",
        "    frames = []\n",
        "\n",
        "    cap = cv2.VideoCapture(video)\n",
        "    while True:\n",
        "        grabbed, frame = cap.read()\n",
        "        if not grabbed:\n",
        "          # print(\"End of video\")\n",
        "          break\n",
        "\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        frame = cv2.resize(frame, shape)\n",
        "\n",
        "        frame = tf.keras.preprocessing.image.img_to_array(\n",
        "            frame) * rescale\n",
        "        frames.append(frame)\n",
        "   \n",
        "\n",
        "    jump = len(frames)//(nbframe+2)\n",
        "    try:\n",
        "      frames = frames[jump::jump][:nbframe]\n",
        "\n",
        "    except Exception as exception:\n",
        "      print(video)\n",
        "      raise exception\n",
        "\n",
        "    images.append(frames)\n",
        "\n",
        "    return np.array(images).reshape(5,500,500,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3y5DIgKVb2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "def audio_to_array(video):\n",
        "  wave,sr = librosa.load(video)\n",
        "  wave = wave[:][45000:150000]\n",
        "  return wave.reshape(wave.shape[0],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPEWZO8mMiEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Diz-6p1ZM5Vg",
        "colab_type": "code",
        "outputId": "4943f2aa-4cf5-42f0-c774-925352142898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        }
      },
      "source": [
        "import sys\n",
        "train_filename = '/content/drive/My Drive/DeepFakeFiles/train.tfrecords'  # address to save the TFRecords file\n",
        "\n",
        "# open the TFRecords file\n",
        "writer = tf.io.TFRecordWriter(train_filename)\n",
        "\n",
        "for i in range(len(train_paths)):\n",
        "    # print how many images are saved every 1000 images\n",
        "    if i % 10 == 0:\n",
        "        print ('Train data: {}/{}'.format(i, len(train_paths)))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    # Load the image\n",
        "    img = image_to_array(train_paths[i])\n",
        "    audio = audio_to_array(train_paths[i])\n",
        "\n",
        "    label = train_labels[i]\n",
        "\n",
        "    # Create a feature\n",
        "    feature = {'train/label': _int64_feature(label),\n",
        "               'train/image': _bytes_feature(tf.compat.as_bytes(img.tostring())),\n",
        "               'train/audio': _bytes_feature(tf.compat.as_bytes(audio.tostring()))}\n",
        "\n",
        "    # Create an example protocol buffer\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "    # Serialize to string and write on the file\n",
        "    writer.write(example.SerializeToString())\n",
        "\n",
        "writer.close()\n",
        "sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data: 0/320\n",
            "Train data: 10/320\n",
            "Train data: 20/320\n",
            "Train data: 30/320\n",
            "Train data: 40/320\n",
            "Train data: 50/320\n",
            "Train data: 60/320\n",
            "Train data: 70/320\n",
            "Train data: 80/320\n",
            "Train data: 90/320\n",
            "Train data: 100/320\n",
            "Train data: 110/320\n",
            "Train data: 120/320\n",
            "Train data: 130/320\n",
            "Train data: 140/320\n",
            "Train data: 150/320\n",
            "Train data: 160/320\n",
            "Train data: 170/320\n",
            "Train data: 180/320\n",
            "Train data: 190/320\n",
            "Train data: 200/320\n",
            "Train data: 210/320\n",
            "Train data: 220/320\n",
            "Train data: 230/320\n",
            "Train data: 240/320\n",
            "Train data: 250/320\n",
            "Train data: 260/320\n",
            "Train data: 270/320\n",
            "Train data: 280/320\n",
            "Train data: 290/320\n",
            "Train data: 300/320\n",
            "Train data: 310/320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRY2Z5Z8i_MN",
        "colab_type": "code",
        "outputId": "fc7b5455-48a1-4dd2-fecf-6095fec1700d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "val_filename = '/content/drive/My Drive/DeepFakeFiles/val.tfrecords'  # address to save the TFRecords file\n",
        "\n",
        "# open the TFRecords file\n",
        "writer = tf.io.TFRecordWriter(val_filename)\n",
        "\n",
        "for i in range(len(val_paths)):\n",
        "    # print how many images are saved every 1000 images\n",
        "    if not i % 100:\n",
        "        print ('Train data: {}/{}'.format(i, len(val_paths)))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    # Load the image\n",
        "    # print(train_paths[i])\n",
        "    img = image_to_array(val_paths[i])\n",
        "    audio = audio_to_array(val_paths[i])\n",
        "\n",
        "    label = val_labels[i]\n",
        "\n",
        "    # Create a feature\n",
        "    feature = {'val/label': _int64_feature(label),\n",
        "               'val/image': _bytes_feature(tf.compat.as_bytes(img.tostring())),\n",
        "               'val/audio': _bytes_feature(tf.compat.as_bytes(audio.tostring()))}\n",
        "\n",
        "    # Create an example protocol buffer\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "    # Serialize to string and write on the file\n",
        "    writer.write(example.SerializeToString())\n",
        "\n",
        "writer.close()\n",
        "print(\"Done\")\n",
        "sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data: 0/80\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrC4ssMOYut9",
        "colab_type": "text"
      },
      "source": [
        "FOR TEST SET RUN THIS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjZQbMqZYy0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "test_paths = glob.glob(\"/content/drive/My Drive/DeepFakeFiles/test_videos/*.mp4\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql2mXCXohAjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path_test = \"/content/drive/My Drive/DeepFakeFiles/test.tfrecords\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lroiwhzghXtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = [0 for _ in range(len(test_paths))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds3BetsbhJYw",
        "colab_type": "code",
        "outputId": "6ac63a00-c0f1-4558-9bbb-ee6f5aab87f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "# open the TFRecords file\n",
        "writer = tf.io.TFRecordWriter(file_path_test)\n",
        "\n",
        "for i in range(len(test_paths)):\n",
        "    # print how many images are saved every 1000 images\n",
        "    if i % 10 == 0:\n",
        "        print ('Test data: {}/{}'.format(i, len(test_paths)))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    # Load the image\n",
        "    img = image_to_array(test_paths[i])\n",
        "    audio = audio_to_array(test_paths[i])\n",
        "\n",
        "    label = test_labels[i]\n",
        "\n",
        "    # Create a feature\n",
        "    feature = {'test/label': _int64_feature(label),\n",
        "               'test/image': _bytes_feature(tf.compat.as_bytes(img.tostring())),\n",
        "               'test/audio': _bytes_feature(tf.compat.as_bytes(audio.tostring()))}\n",
        "\n",
        "    # Create an example protocol buffer\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "    # Serialize to string and write on the file\n",
        "    writer.write(example.SerializeToString())\n",
        "\n",
        "writer.close()\n",
        "sys.stdout.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data: 0/400\n",
            "Test data: 10/400\n",
            "Test data: 20/400\n",
            "Test data: 30/400\n",
            "Test data: 40/400\n",
            "Test data: 50/400\n",
            "Test data: 60/400\n",
            "Test data: 70/400\n",
            "Test data: 80/400\n",
            "Test data: 90/400\n",
            "Test data: 100/400\n",
            "Test data: 110/400\n",
            "Test data: 120/400\n",
            "Test data: 130/400\n",
            "Test data: 140/400\n",
            "Test data: 150/400\n",
            "Test data: 160/400\n",
            "Test data: 170/400\n",
            "Test data: 180/400\n",
            "Test data: 190/400\n",
            "Test data: 200/400\n",
            "Test data: 210/400\n",
            "Test data: 220/400\n",
            "Test data: 230/400\n",
            "Test data: 240/400\n",
            "Test data: 250/400\n",
            "Test data: 260/400\n",
            "Test data: 270/400\n",
            "Test data: 280/400\n",
            "Test data: 290/400\n",
            "Test data: 300/400\n",
            "Test data: 310/400\n",
            "Test data: 320/400\n",
            "Test data: 330/400\n",
            "Test data: 340/400\n",
            "Test data: 350/400\n",
            "Test data: 360/400\n",
            "Test data: 370/400\n",
            "Test data: 380/400\n",
            "Test data: 390/400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qPVZQIb1uqS",
        "colab_type": "code",
        "outputId": "82a0dcf0-5315-4bf4-f47b-cee524f1a5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      }
    }
  ]
}
