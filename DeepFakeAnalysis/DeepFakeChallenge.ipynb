{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "M21kMvlUCcoW",
    "outputId": "740263f9-ff9d-4bb4-b745-3f0a8607e5ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n",
      "2.1.0-rc1\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import os,cv2,io\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jn6wfd26IFNF"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "    \n",
    "# Select appropriate distribution strategy\n",
    "if tpu:\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.experimental.TPUStrategy(tpu) # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDX8VOOKDKPA"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/My Drive/DeepFakeFiles/train.tfrecords'\n",
    "file_name = '/content/drive/My Drive/DeepFakeFiles/val.tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "l5meNMEHE8Ao",
    "outputId": "1133bb11-799e-4cd0-8553-7a37c279e39b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (((5, 350, 350, 1), (105000, 1)), (1,)), types: ((tf.float32, tf.float32), tf.float32)>\n",
      "<MapDataset shapes: (((5, 350, 350, 1), (105000, 1)), (1,)), types: ((tf.float32, tf.float32), tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "filenames = [data_path]\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "val_dataset = tf.data.TFRecordDataset([file_name]) \n",
    "\n",
    "feature = {'train/image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'train/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "           'train/audio': tf.io.FixedLenFeature([], tf.string),}\n",
    "\n",
    "\n",
    "features_val = {'val/image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'val/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "           'val/audio': tf.io.FixedLenFeature([], tf.string),}\n",
    "\n",
    "def _parse_function_val(example_proto):\n",
    "  features = tf.io.parse_single_example(example_proto, features_val)\n",
    "  audio_raw = tf.io.decode_raw(features['val/audio'],tf.float32)\n",
    "  audio = tf.reshape(audio_raw,shape=(105000,1))\n",
    "\n",
    "  image_raw = tf.io.decode_raw(features['val/image'],tf.float32)\n",
    "  image = tf.reshape(image_raw,[5,500,500,3])\n",
    "  image = tf.image.rgb_to_grayscale(image)\n",
    "  image = tf.image.resize(image,(350,350))\n",
    "  labels =features['val/label']\n",
    "  labels = tf.one_hot(labels,depth=1) \n",
    "  return (image,audio),labels\n",
    "\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "  features = tf.io.parse_single_example(example_proto, feature)\n",
    "  audio_raw = tf.io.decode_raw(features['train/audio'],tf.float32)\n",
    "  audio = tf.reshape(audio_raw,shape=(105000,1))\n",
    "\n",
    "  image_raw = tf.io.decode_raw(features['train/image'],tf.float32)\n",
    "  image = tf.reshape(image_raw,[5,500,500,3])\n",
    "  image = tf.image.rgb_to_grayscale(image)\n",
    "  image = tf.image.resize(image,(350,350))\n",
    "\n",
    "  labels =features['train/label']\n",
    "  labels = tf.one_hot(labels,depth=1)\n",
    "  return (image,audio),labels\n",
    "\n",
    "dataset = raw_dataset.map(_parse_function)\n",
    "print(dataset)\n",
    "val = val_dataset.map(_parse_function_val)\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "BS6suPsu7L0A",
    "outputId": "0db16033-70a0-4b18-e3e5-afff24bed111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: (((None, 5, 350, 350, 1), (None, 105000, 1)), (None, 1)), types: ((tf.float32, tf.float32), tf.float32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: (((None, 5, 350, 350, 1), (None, 105000, 1)), (None, 1)), types: ((tf.float32, tf.float32), tf.float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 4\n",
    "BUFFER_SIZE = 10\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "print(dataset)\n",
    "valid = val.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvQPaNet7oYn"
   },
   "outputs": [],
   "source": [
    "def action_model(shape):\n",
    "    inputs = tf.keras.layers.Input(shape=shape)\n",
    "    convLSTM1 = tf.keras.layers.ConvLSTM2D(filters=16,kernel_size=(3,3),return_sequences=True)(inputs)\n",
    "    BN1 = tf.keras.layers.BatchNormalization()(convLSTM1)\n",
    "    # convLSTM2 = tf.keras.layers.ConvLSTM2D(filters=32,kernel_size=(2,2),return_sequences=True)(BN1)\n",
    "    # BN2= tf.keras.layers.BatchNormalization()(convLSTM2)\n",
    "    flatten = tf.keras.layers.Flatten()(BN1)\n",
    "    # dense1 = tf.keras.layers.Dense(64)(flatten)\n",
    "    dense2 = tf.keras.layers.Dense(32,activation='relu')(flatten)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=dense2)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETJjPP6C75EO"
   },
   "outputs": [],
   "source": [
    "def audio_and_final_model(shape):\n",
    "  input_shape = tf.keras.layers.Input(shape=shape)\n",
    "  Conv1 = tf.keras.layers.Conv1D(16,activation='relu',kernel_size=(10))(input_shape)\n",
    "  MaxPool1 = tf.keras.layers.MaxPool1D()(Conv1)\n",
    "  BatchNorm1 = tf.keras.layers.BatchNormalization()(MaxPool1)\n",
    "  Dropout1 = tf.keras.layers.Dropout(0.4)(BatchNorm1)\n",
    "  Conv2 = tf.keras.layers.Conv1D(32,activation='relu',kernel_size=(10))(Dropout1)\n",
    "  MaxPool2 = tf.keras.layers.MaxPool1D()(Conv2)\n",
    "  # Dropout2 = tf.keras.layers.Dropout(0.4)(MaxPool2)\n",
    "  # Conv3 = tf.keras.layers.Conv1D(16,activation='relu',kernel_size=(10))(Dropout1)\n",
    "  # MaxPool3 = tf.keras.layers.MaxPool1D()(Conv3)\n",
    "  # Dropout3 = tf.keras.layers.Dropout(0.4)(MaxPool3)\n",
    "  Flatten = tf.keras.layers.Flatten()(MaxPool2)\n",
    "  # Dense1 = tf.keras.layers.Dense(128,activation='relu')(Flatten)\n",
    "  # Dense2 = tf.keras.layers.Dense(64,activation='relu')(Flatten)\n",
    "  Dense3 = tf.keras.layers.Dense(32,activation='relu')(Flatten)\n",
    "\n",
    "  model = tf.keras.models.Model(inputs=input_shape,outputs=Dense3)\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "vcN5uOgl8KFX",
    "outputId": "cc9fb758-dc71-4e5a-dc6a-2a2cbe0ca50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pU5AY8zRw-Oa",
    "outputId": "44e6409a-bd3a-4d4c-f466-ff58ac31c0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 5, 350, 350, 1)]  0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 5, 348, 348, 16)   9856      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 348, 348, 16)   64        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9688320)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                310026272 \n",
      "=================================================================\n",
      "Total params: 310,036,192\n",
      "Trainable params: 310,036,160\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 105000, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 104991, 16)   176         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 52495, 16)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 52495, 16)    64          max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 5, 350, 350, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 52495, 16)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)       (None, 5, 348, 348,  9856        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 52486, 32)    5152        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 5, 348, 348,  64          conv_lst_m2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 26243, 32)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9688320)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 839776)       0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           310026272   flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           26872864    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            33          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 336,916,561\n",
      "Trainable params: 336,916,497\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "am = action_model((5, 350, 350, 1))\n",
    "afm = audio_and_final_model((105000,1))\n",
    "\n",
    "combined = tf.keras.layers.Concatenate(axis=-1)([am.output,afm.output])\n",
    "z = tf.keras.layers.Dense(32,activation='relu')(combined)\n",
    "# den1 = tf.keras.layers.Dense(64,activation='relu')(z)\n",
    "# den2 = tf.keras.layers.Dense(32,activation='relu')(z)\n",
    "dropOut = tf.keras.layers.Dropout(0.3)(z)\n",
    "out = tf.keras.layers.Dense(1,activation='sigmoid')(dropOut)\n",
    "model = tf.keras.models.Model(inputs=[am.input,afm.input],outputs=out)\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "OrOk6D2M8Ode",
    "outputId": "00a6a971-b8f1-41a9-be4d-2ab5f5ca237f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Train for 80 steps, validate for 20 steps\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 127s 2s/step - loss: 287.3501 - accuracy: 0.6375 - val_loss: 5.9388 - val_accuracy: 0.5250\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 17.3463 - accuracy: 0.7031 - val_loss: 0.5768 - val_accuracy: 0.8250\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 44s 547ms/step - loss: 0.6280 - accuracy: 0.7906 - val_loss: 0.4541 - val_accuracy: 0.8250\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.5425 - accuracy: 0.8000 - val_loss: 0.4423 - val_accuracy: 0.8250\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.4927 - accuracy: 0.7937 - val_loss: 0.4685 - val_accuracy: 0.8125\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.4971 - accuracy: 0.8094 - val_loss: 0.4927 - val_accuracy: 0.8250\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.4528 - accuracy: 0.8062 - val_loss: 0.4953 - val_accuracy: 0.8250\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.4573 - accuracy: 0.8313 - val_loss: 0.5033 - val_accuracy: 0.8125\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.4581 - accuracy: 0.8219 - val_loss: 0.6471 - val_accuracy: 0.7875\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.5028 - accuracy: 0.8344 - val_loss: 0.5183 - val_accuracy: 0.7875\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.4241 - accuracy: 0.8406 - val_loss: 0.6456 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.4276 - accuracy: 0.8313 - val_loss: 0.5916 - val_accuracy: 0.7625\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.4185 - accuracy: 0.8344 - val_loss: 0.5803 - val_accuracy: 0.7625\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.3502 - accuracy: 0.8562 - val_loss: 0.7032 - val_accuracy: 0.7625\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.3199 - accuracy: 0.8562 - val_loss: 0.6455 - val_accuracy: 0.7125\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.3208 - accuracy: 0.8719 - val_loss: 0.7752 - val_accuracy: 0.7250\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.3160 - accuracy: 0.8687 - val_loss: 0.7449 - val_accuracy: 0.7250\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.3998 - accuracy: 0.8281 - val_loss: 0.6425 - val_accuracy: 0.7875\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.3333 - accuracy: 0.8625 - val_loss: 0.8062 - val_accuracy: 0.7250\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2673 - accuracy: 0.8750 - val_loss: 1.0732 - val_accuracy: 0.6875\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2823 - accuracy: 0.8687 - val_loss: 1.0849 - val_accuracy: 0.7625\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2849 - accuracy: 0.8625 - val_loss: 0.8735 - val_accuracy: 0.7625\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2813 - accuracy: 0.8687 - val_loss: 1.1179 - val_accuracy: 0.7375\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 44s 547ms/step - loss: 0.2760 - accuracy: 0.8813 - val_loss: 1.1199 - val_accuracy: 0.7125\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2552 - accuracy: 0.8750 - val_loss: 1.1841 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2644 - accuracy: 0.8781 - val_loss: 1.7383 - val_accuracy: 0.6500\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.4703 - accuracy: 0.8687 - val_loss: 1.0182 - val_accuracy: 0.7625\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2519 - accuracy: 0.8813 - val_loss: 1.2256 - val_accuracy: 0.7250\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2403 - accuracy: 0.8781 - val_loss: 1.1103 - val_accuracy: 0.7250\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2426 - accuracy: 0.8844 - val_loss: 1.3229 - val_accuracy: 0.7250\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2427 - accuracy: 0.8813 - val_loss: 1.3774 - val_accuracy: 0.7375\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2231 - accuracy: 0.8969 - val_loss: 1.4362 - val_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2314 - accuracy: 0.8875 - val_loss: 1.3997 - val_accuracy: 0.7375\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2330 - accuracy: 0.8938 - val_loss: 1.5917 - val_accuracy: 0.7375\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2199 - accuracy: 0.8969 - val_loss: 1.9962 - val_accuracy: 0.7500\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2520 - accuracy: 0.8844 - val_loss: 2.3718 - val_accuracy: 0.7625\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2187 - accuracy: 0.8875 - val_loss: 2.1386 - val_accuracy: 0.7500\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2186 - accuracy: 0.8906 - val_loss: 2.2708 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1919 - accuracy: 0.8938 - val_loss: 2.5180 - val_accuracy: 0.7625\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2008 - accuracy: 0.8969 - val_loss: 2.2836 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2186 - accuracy: 0.8875 - val_loss: 2.4240 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2021 - accuracy: 0.8875 - val_loss: 2.9167 - val_accuracy: 0.7625\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.2107 - accuracy: 0.8906 - val_loss: 4.2331 - val_accuracy: 0.7625\n",
      "Epoch 44/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.2474 - accuracy: 0.8987\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "80/80 [==============================] - 44s 546ms/step - loss: 0.2519 - accuracy: 0.8969 - val_loss: 2.0253 - val_accuracy: 0.7125\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1879 - accuracy: 0.8969 - val_loss: 2.1163 - val_accuracy: 0.7250\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1905 - accuracy: 0.8969 - val_loss: 2.1471 - val_accuracy: 0.7250\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 44s 544ms/step - loss: 0.1925 - accuracy: 0.8969 - val_loss: 2.1685 - val_accuracy: 0.7250\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1856 - accuracy: 0.8906 - val_loss: 2.2008 - val_accuracy: 0.7250\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1831 - accuracy: 0.8938 - val_loss: 2.2714 - val_accuracy: 0.7250\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1843 - accuracy: 0.9000 - val_loss: 2.3870 - val_accuracy: 0.7250\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1885 - accuracy: 0.8969 - val_loss: 2.4067 - val_accuracy: 0.7375\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1872 - accuracy: 0.8969 - val_loss: 2.4426 - val_accuracy: 0.7375\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1891 - accuracy: 0.9062 - val_loss: 2.4491 - val_accuracy: 0.7375\n",
      "Epoch 54/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1856 - accuracy: 0.8956\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1851 - accuracy: 0.8969 - val_loss: 2.4435 - val_accuracy: 0.7375\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1770 - accuracy: 0.9000 - val_loss: 2.4511 - val_accuracy: 0.7375\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 44s 544ms/step - loss: 0.1763 - accuracy: 0.9000 - val_loss: 2.4611 - val_accuracy: 0.7375\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1839 - accuracy: 0.8969 - val_loss: 2.4656 - val_accuracy: 0.7375\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1826 - accuracy: 0.9000 - val_loss: 2.4680 - val_accuracy: 0.7375\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1839 - accuracy: 0.9031 - val_loss: 2.4730 - val_accuracy: 0.7375\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 44s 544ms/step - loss: 0.1758 - accuracy: 0.8969 - val_loss: 2.4748 - val_accuracy: 0.7375\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1840 - accuracy: 0.8938 - val_loss: 2.4755 - val_accuracy: 0.7375\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1762 - accuracy: 0.8969 - val_loss: 2.4836 - val_accuracy: 0.7375\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1899 - accuracy: 0.8875 - val_loss: 2.4880 - val_accuracy: 0.7375\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1836 - accuracy: 0.9000 - val_loss: 2.4915 - val_accuracy: 0.7375\n",
      "Epoch 65/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1905 - accuracy: 0.8956\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1885 - accuracy: 0.8969 - val_loss: 2.4916 - val_accuracy: 0.7375\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1791 - accuracy: 0.8969 - val_loss: 2.4923 - val_accuracy: 0.7375\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1802 - accuracy: 0.8906 - val_loss: 2.4934 - val_accuracy: 0.7375\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 44s 544ms/step - loss: 0.1799 - accuracy: 0.9031 - val_loss: 2.4940 - val_accuracy: 0.7375\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1752 - accuracy: 0.8969 - val_loss: 2.4951 - val_accuracy: 0.7375\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1768 - accuracy: 0.9000 - val_loss: 2.4956 - val_accuracy: 0.7375\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1882 - accuracy: 0.8938 - val_loss: 2.4959 - val_accuracy: 0.7375\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 44s 544ms/step - loss: 0.1752 - accuracy: 0.8906 - val_loss: 2.4965 - val_accuracy: 0.7375\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1790 - accuracy: 0.9000 - val_loss: 2.4974 - val_accuracy: 0.7375\n",
      "Epoch 74/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.8956\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1764 - accuracy: 0.8969 - val_loss: 2.4981 - val_accuracy: 0.7375\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 44s 544ms/step - loss: 0.1703 - accuracy: 0.9031 - val_loss: 2.4980 - val_accuracy: 0.7375\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1828 - accuracy: 0.8938 - val_loss: 2.4983 - val_accuracy: 0.7375\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1773 - accuracy: 0.8969 - val_loss: 2.4984 - val_accuracy: 0.7375\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1731 - accuracy: 0.9031 - val_loss: 2.4984 - val_accuracy: 0.7375\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1794 - accuracy: 0.8938 - val_loss: 2.4984 - val_accuracy: 0.7375\n",
      "Epoch 80/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.8956\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1888 - accuracy: 0.8969 - val_loss: 2.4985 - val_accuracy: 0.7375\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 44s 544ms/step - loss: 0.2283 - accuracy: 0.8969 - val_loss: 2.4987 - val_accuracy: 0.7375\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1772 - accuracy: 0.8938 - val_loss: 2.4987 - val_accuracy: 0.7375\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1825 - accuracy: 0.9062 - val_loss: 2.4986 - val_accuracy: 0.7375\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1833 - accuracy: 0.9031 - val_loss: 2.4985 - val_accuracy: 0.7375\n",
      "Epoch 85/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.8861\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1836 - accuracy: 0.8875 - val_loss: 2.4985 - val_accuracy: 0.7375\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1753 - accuracy: 0.9062 - val_loss: 2.4986 - val_accuracy: 0.7375\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1827 - accuracy: 0.9031 - val_loss: 2.4985 - val_accuracy: 0.7375\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1785 - accuracy: 0.9000 - val_loss: 2.4987 - val_accuracy: 0.7375\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1891 - accuracy: 0.8969 - val_loss: 2.4982 - val_accuracy: 0.7375\n",
      "Epoch 90/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.9019\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1837 - accuracy: 0.8969 - val_loss: 2.4985 - val_accuracy: 0.7375\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1815 - accuracy: 0.8906 - val_loss: 2.4985 - val_accuracy: 0.7375\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1745 - accuracy: 0.9000 - val_loss: 2.4988 - val_accuracy: 0.7375\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1755 - accuracy: 0.9000 - val_loss: 2.4987 - val_accuracy: 0.7375\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1807 - accuracy: 0.8969 - val_loss: 2.4985 - val_accuracy: 0.7375\n",
      "Epoch 95/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.8987\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1804 - accuracy: 0.8969 - val_loss: 2.4987 - val_accuracy: 0.7375\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1879 - accuracy: 0.8875 - val_loss: 2.4987 - val_accuracy: 0.7375\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1838 - accuracy: 0.8906 - val_loss: 2.4988 - val_accuracy: 0.7375\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1762 - accuracy: 0.8906 - val_loss: 2.4988 - val_accuracy: 0.7375\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1772 - accuracy: 0.9000 - val_loss: 2.4988 - val_accuracy: 0.7375\n",
      "Epoch 100/100\n",
      "79/80 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9019\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "80/80 [==============================] - 44s 545ms/step - loss: 0.1798 - accuracy: 0.9000 - val_loss: 2.4987 - val_accuracy: 0.7375\n",
      "Saving Model\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(verbose=1,monitor='loss',patience=5,min_delta=1e-6)]\n",
    "\n",
    "print(\"Starting training\")\n",
    "model.fit(dataset,epochs=EPOCHS,callbacks=callbacks,steps_per_epoch=80,validation_data=valid,validation_steps=20)\n",
    "print(\"Saving Model\")\n",
    "model.save(\"/content/drive/My Drive/DeepFakeFiles/DeepFakeModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuV8A6UvuK-h"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"/content/drive/My Drive/DeepFakeFiles/Checkpoints/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pb6P41YvFlVn"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "model = tf.keras.models.load_model(\"/content/drive/My Drive/DeepFakeFiles/SecondModel.h5\")\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','val_acc'])\n",
    "callbacks = [tf.keras.callbacks.ReduceLROnPlateau(verbose=1,monitor='loss',patience=5),tf.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/DeepFakeFiles/SecondModel.h5',verbose=1,monitor='loss',save_best_only=True,save_freq='epoch',save_weights_only=True),tf.keras.callbacks.TensorBoard()]\n",
    "print(\"Starting training\")\n",
    "model.fit(dataset,epochs=EPOCHS,callbacks=callbacks,steps_per_epoch=100,validation_data=valid,validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jwGED3XE62Dy"
   },
   "outputs": [],
   "source": [
    "# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir '/content/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjfEdVnK-Mbd"
   },
   "source": [
    "TESTING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCNSc_e2SfUR"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.TFRecordDataset(\"/content/drive/My Drive/DeepFakeFiles/test.tfrecords\")\n",
    "\n",
    "features_test = {'test/image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'test/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "           'test/audio': tf.io.FixedLenFeature([], tf.string),}\n",
    "\n",
    "def _parse_function_test(example_proto):\n",
    "  features = tf.io.parse_single_example(example_proto, features_test)\n",
    "  audio_raw = tf.io.decode_raw(features['test/audio'],tf.float32)\n",
    "  audio = tf.reshape(audio_raw,shape=(105000,1))\n",
    "\n",
    "  image_raw = tf.io.decode_raw(features['test/image'],tf.float32)\n",
    "  image = tf.reshape(image_raw,[5,500,500,3])\n",
    "  image = tf.image.rgb_to_grayscale(image)\n",
    "  image = tf.image.resize(image,(350,350))\n",
    "  labels =features['test/label']\n",
    "  labels = tf.one_hot(labels,depth=1) \n",
    "  return (image,audio),labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SiF3_92tvBOq",
    "outputId": "8b9bb075-e259-4103-8f85-d60b5e07b3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (((5, 350, 350, 1), (105000, 1)), (1,)), types: ((tf.float32, tf.float32), tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(_parse_function_test)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EgMVFpwdvOZV",
    "outputId": "e6919f1c-15ae-4430-e95b-d3cf090ecc80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: (((None, 5, 350, 350, 1), (None, 105000, 1)), (None, 1)), types: ((tf.float32, tf.float32), tf.float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_dataset.batch(BATCH_SIZE).repeat()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ydRm0uhdvcB9",
    "outputId": "a1135d8d-a606-4683-fbf9-324ecde0c4f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 131s 1s/step\n",
      "[[4.91826739e-08]\n",
      " [6.41587451e-02]\n",
      " [1.08890049e-01]\n",
      " [1.36651397e-01]\n",
      " [6.82397140e-03]\n",
      " [4.99885827e-01]\n",
      " [9.60812271e-01]\n",
      " [2.19488011e-05]\n",
      " [9.99962926e-01]\n",
      " [8.96965340e-02]\n",
      " [4.59584929e-02]\n",
      " [7.35937238e-06]\n",
      " [5.38711250e-02]\n",
      " [1.00000000e+00]\n",
      " [3.39367129e-02]\n",
      " [1.05553642e-02]\n",
      " [1.25744293e-04]\n",
      " [1.57567528e-10]\n",
      " [1.86705403e-03]\n",
      " [2.27522268e-09]\n",
      " [2.86584691e-06]\n",
      " [1.00000000e+00]\n",
      " [2.83398037e-07]\n",
      " [1.71117187e-01]\n",
      " [9.05862635e-06]\n",
      " [9.16126091e-03]\n",
      " [9.89413202e-01]\n",
      " [1.76853556e-02]\n",
      " [5.82880937e-02]\n",
      " [1.44009873e-01]\n",
      " [6.04730174e-02]\n",
      " [1.32031962e-01]\n",
      " [4.99885827e-01]\n",
      " [4.99885827e-01]\n",
      " [1.25744293e-04]\n",
      " [2.09695369e-01]\n",
      " [6.54853821e-01]\n",
      " [6.84426874e-02]\n",
      " [2.66822837e-02]\n",
      " [3.64856482e-01]\n",
      " [2.94143980e-08]\n",
      " [1.73023082e-02]\n",
      " [2.54347716e-02]\n",
      " [5.64808249e-01]\n",
      " [1.08890049e-01]\n",
      " [1.15575112e-01]\n",
      " [5.71611404e-01]\n",
      " [3.56033146e-01]\n",
      " [5.58459287e-05]\n",
      " [3.74714799e-12]\n",
      " [1.04572615e-02]\n",
      " [1.29941687e-01]\n",
      " [3.37775331e-03]\n",
      " [4.96367574e-01]\n",
      " [6.74898038e-03]\n",
      " [2.31841623e-05]\n",
      " [5.27854785e-02]\n",
      " [1.58765268e-09]\n",
      " [9.93860841e-01]\n",
      " [4.28235292e-01]\n",
      " [2.66822837e-02]\n",
      " [8.72507691e-01]\n",
      " [3.49656604e-02]\n",
      " [1.00000000e+00]\n",
      " [1.18280146e-02]\n",
      " [9.93860841e-01]\n",
      " [4.57234792e-02]\n",
      " [9.36096847e-01]\n",
      " [3.60986875e-13]\n",
      " [9.99999404e-01]\n",
      " [1.64326616e-02]\n",
      " [1.96972847e-01]\n",
      " [8.43720615e-01]\n",
      " [3.46174170e-06]\n",
      " [1.56841561e-01]\n",
      " [5.32133460e-01]\n",
      " [2.79465884e-01]\n",
      " [4.96367574e-01]\n",
      " [8.32028210e-01]\n",
      " [2.75249481e-01]\n",
      " [4.92779713e-04]\n",
      " [1.07540870e-02]\n",
      " [1.30596574e-08]\n",
      " [3.24802339e-01]\n",
      " [2.53759883e-02]\n",
      " [9.43434477e-01]\n",
      " [1.00000000e+00]\n",
      " [6.81531876e-02]\n",
      " [5.58459287e-05]\n",
      " [3.64856482e-01]\n",
      " [1.21878915e-01]\n",
      " [1.68048771e-07]\n",
      " [3.37775331e-03]\n",
      " [2.62368709e-01]\n",
      " [8.10929775e-01]\n",
      " [1.83903962e-01]\n",
      " [3.54898512e-01]\n",
      " [9.33614851e-04]\n",
      " [1.00000000e+00]\n",
      " [6.26345649e-02]\n",
      " [6.52476621e-04]\n",
      " [6.70582801e-02]\n",
      " [7.23479167e-02]\n",
      " [7.83695400e-01]\n",
      " [8.14024825e-03]\n",
      " [1.05314008e-04]\n",
      " [1.72770470e-01]\n",
      " [3.39367129e-02]\n",
      " [2.09695369e-01]\n",
      " [1.00000000e+00]\n",
      " [3.64856482e-01]\n",
      " [2.27522268e-09]\n",
      " [9.91564631e-01]\n",
      " [9.90833342e-01]\n",
      " [1.39193133e-01]\n",
      " [2.78732926e-01]\n",
      " [8.78261775e-02]\n",
      " [8.49761590e-02]\n",
      " [1.41494034e-04]\n",
      " [6.93723440e-01]\n",
      " [1.44792676e-01]\n",
      " [6.36853054e-02]\n",
      " [1.22413598e-01]\n",
      " [1.86143744e-12]\n",
      " [9.59204435e-01]\n",
      " [5.70129603e-02]\n",
      " [4.72331434e-01]\n",
      " [1.21491671e-01]\n",
      " [1.73023082e-02]\n",
      " [6.34901077e-02]\n",
      " [9.33614851e-04]\n",
      " [3.60986875e-13]\n",
      " [2.03907916e-06]\n",
      " [2.15848848e-01]\n",
      " [1.20426854e-03]\n",
      " [7.59608625e-03]\n",
      " [9.05862635e-06]\n",
      " [9.31945801e-01]\n",
      " [1.48032799e-01]\n",
      " [6.37910541e-14]\n",
      " [1.00000000e+00]\n",
      " [1.68048771e-07]\n",
      " [3.21364045e-01]\n",
      " [9.99086499e-01]\n",
      " [1.08890049e-01]\n",
      " [5.70775956e-05]\n",
      " [9.61989939e-01]\n",
      " [1.50459975e-01]\n",
      " [1.23063229e-01]\n",
      " [4.99829166e-02]\n",
      " [5.71611404e-01]\n",
      " [8.52065627e-03]\n",
      " [3.38580698e-01]\n",
      " [1.46013737e-01]\n",
      " [1.50459975e-01]\n",
      " [2.62783762e-12]\n",
      " [7.10171580e-01]\n",
      " [1.58195253e-05]\n",
      " [1.05820015e-01]\n",
      " [4.76151854e-02]\n",
      " [4.72547412e-01]\n",
      " [3.35908048e-02]\n",
      " [3.35916644e-03]\n",
      " [9.16126091e-03]\n",
      " [4.74422164e-02]\n",
      " [9.90844309e-01]\n",
      " [6.54236153e-02]\n",
      " [9.99892235e-01]\n",
      " [1.35670140e-01]\n",
      " [1.22362366e-02]\n",
      " [1.97596266e-04]\n",
      " [2.95166016e-01]\n",
      " [5.45600474e-01]\n",
      " [5.05974352e-01]\n",
      " [9.58315253e-01]\n",
      " [8.55997764e-03]\n",
      " [1.18403872e-02]\n",
      " [2.62783762e-12]\n",
      " [8.88119578e-01]\n",
      " [2.52795607e-01]\n",
      " [1.27319977e-01]\n",
      " [7.59608625e-03]\n",
      " [2.59503258e-06]\n",
      " [4.66050319e-02]\n",
      " [9.90649164e-01]\n",
      " [2.21069846e-02]\n",
      " [7.96168204e-03]\n",
      " [9.80684757e-01]\n",
      " [7.67130017e-01]\n",
      " [1.23063229e-01]\n",
      " [9.36096847e-01]\n",
      " [6.48292335e-05]\n",
      " [2.01137066e-01]\n",
      " [1.55333487e-06]\n",
      " [8.88119578e-01]\n",
      " [3.37823830e-03]\n",
      " [5.96108846e-03]\n",
      " [1.03973523e-02]\n",
      " [1.83903962e-01]\n",
      " [1.00000000e+00]\n",
      " [2.21069846e-02]\n",
      " [1.76853556e-02]\n",
      " [7.09579069e-07]\n",
      " [3.05998808e-04]\n",
      " [4.28235292e-01]\n",
      " [3.25325876e-01]\n",
      " [1.00000000e+00]\n",
      " [5.63044362e-02]\n",
      " [1.89314168e-02]\n",
      " [9.90477204e-03]\n",
      " [3.38486508e-02]\n",
      " [2.79465884e-01]\n",
      " [1.19489329e-02]\n",
      " [3.65231544e-01]\n",
      " [1.31129727e-01]\n",
      " [1.23063229e-01]\n",
      " [4.16211754e-01]\n",
      " [1.00000000e+00]\n",
      " [4.08851385e-01]\n",
      " [1.00000000e+00]\n",
      " [2.93102488e-03]\n",
      " [3.86395216e-01]\n",
      " [4.51153982e-03]\n",
      " [1.60564151e-09]\n",
      " [1.68946907e-01]\n",
      " [2.03907916e-06]\n",
      " [9.98491406e-01]\n",
      " [4.73126303e-03]\n",
      " [9.31945801e-01]\n",
      " [3.64856482e-01]\n",
      " [1.07540870e-02]\n",
      " [2.67339812e-04]\n",
      " [2.18010433e-02]\n",
      " [9.91942048e-01]\n",
      " [5.71680721e-05]\n",
      " [7.09579069e-07]\n",
      " [1.15575112e-01]\n",
      " [3.58512290e-02]\n",
      " [2.15826139e-01]\n",
      " [1.49542087e-04]\n",
      " [8.78261775e-02]\n",
      " [1.43134866e-06]\n",
      " [4.72547412e-01]\n",
      " [1.06990710e-02]\n",
      " [4.28235292e-01]\n",
      " [1.00000000e+00]\n",
      " [8.54549825e-01]\n",
      " [2.13133082e-01]\n",
      " [3.48380813e-03]\n",
      " [9.38182414e-01]\n",
      " [1.46013737e-01]\n",
      " [1.48220789e-02]\n",
      " [5.70129603e-02]\n",
      " [3.04823160e-01]\n",
      " [3.02567860e-05]\n",
      " [4.72615838e-01]\n",
      " [1.41701505e-01]\n",
      " [6.57506348e-07]\n",
      " [3.76195401e-01]\n",
      " [3.21966829e-04]\n",
      " [1.07540870e-02]\n",
      " [2.21069846e-02]\n",
      " [8.34058464e-01]\n",
      " [3.78638310e-06]\n",
      " [5.71611404e-01]\n",
      " [1.49542087e-04]\n",
      " [3.35908048e-02]\n",
      " [7.86151066e-02]\n",
      " [9.74683523e-01]\n",
      " [1.19901814e-01]\n",
      " [8.78020301e-02]\n",
      " [2.03907916e-06]\n",
      " [1.21491671e-01]\n",
      " [1.05553642e-02]\n",
      " [8.60445619e-01]\n",
      " [6.57506348e-07]\n",
      " [5.36758117e-02]\n",
      " [6.74190698e-03]\n",
      " [2.14494199e-01]\n",
      " [2.52795607e-01]\n",
      " [3.04823160e-01]\n",
      " [1.22413598e-01]\n",
      " [5.68144247e-02]\n",
      " [2.27522268e-09]\n",
      " [1.00000000e+00]\n",
      " [5.71611404e-01]\n",
      " [9.90477204e-03]\n",
      " [9.61855114e-01]\n",
      " [5.15956394e-02]\n",
      " [2.27892071e-01]\n",
      " [1.73023082e-02]\n",
      " [1.16429895e-01]\n",
      " [3.39266151e-01]\n",
      " [7.23479167e-02]\n",
      " [8.90099034e-02]\n",
      " [5.15956394e-02]\n",
      " [2.99763978e-01]\n",
      " [6.82397140e-03]\n",
      " [4.69081067e-02]\n",
      " [1.07540870e-02]\n",
      " [1.21491671e-01]\n",
      " [3.76216173e-01]\n",
      " [6.74190698e-03]\n",
      " [2.99763978e-01]\n",
      " [6.09454453e-01]\n",
      " [1.50459975e-01]\n",
      " [1.35670140e-01]\n",
      " [1.84712037e-01]\n",
      " [5.95888793e-02]\n",
      " [9.90833342e-01]\n",
      " [6.42388761e-02]\n",
      " [6.42388761e-02]\n",
      " [1.16429895e-01]\n",
      " [8.45615149e-01]\n",
      " [1.00000000e+00]\n",
      " [4.92599048e-02]\n",
      " [1.00000000e+00]\n",
      " [2.05044895e-01]\n",
      " [6.54853821e-01]\n",
      " [1.41263651e-02]\n",
      " [9.99999881e-01]\n",
      " [3.40461220e-17]\n",
      " [2.70752683e-02]\n",
      " [9.33614851e-04]\n",
      " [1.06990710e-02]\n",
      " [2.55127106e-05]\n",
      " [1.71028121e-04]\n",
      " [1.08890049e-01]\n",
      " [1.35013506e-01]\n",
      " [8.49555188e-04]\n",
      " [1.21491671e-01]\n",
      " [3.44209641e-01]\n",
      " [1.30596574e-08]\n",
      " [4.08851385e-01]\n",
      " [1.05820015e-01]\n",
      " [9.98491406e-01]\n",
      " [8.86171758e-01]\n",
      " [2.10115337e-03]\n",
      " [3.63659486e-03]\n",
      " [6.04730174e-02]\n",
      " [6.70582801e-02]\n",
      " [1.83903962e-01]\n",
      " [1.64732424e-04]\n",
      " [5.15956394e-02]\n",
      " [9.46102023e-01]\n",
      " [9.99998927e-01]\n",
      " [8.78020301e-02]\n",
      " [8.88119578e-01]\n",
      " [1.83903962e-01]\n",
      " [1.67343296e-05]\n",
      " [1.00000000e+00]\n",
      " [6.09454453e-01]\n",
      " [5.51695414e-02]\n",
      " [1.60020590e-01]\n",
      " [5.15956394e-02]\n",
      " [6.74190698e-03]\n",
      " [7.52484426e-03]\n",
      " [2.54347716e-02]\n",
      " [5.70129603e-02]\n",
      " [1.00000000e+00]\n",
      " [1.86705403e-03]\n",
      " [1.94239467e-02]\n",
      " [3.34295891e-02]\n",
      " [3.81581217e-01]\n",
      " [9.90477204e-03]\n",
      " [3.05309564e-01]\n",
      " [4.33463067e-01]\n",
      " [2.37263587e-09]\n",
      " [2.43059658e-05]\n",
      " [7.26709026e-04]\n",
      " [1.68946907e-01]\n",
      " [5.05974352e-01]\n",
      " [6.34964416e-03]\n",
      " [2.14494199e-01]\n",
      " [4.28235292e-01]\n",
      " [6.23843744e-02]\n",
      " [9.14012606e-04]\n",
      " [2.44378019e-02]\n",
      " [3.32231857e-02]\n",
      " [1.00000000e+00]\n",
      " [9.96725559e-01]\n",
      " [9.76209342e-02]\n",
      " [5.32253552e-03]\n",
      " [2.15848848e-01]\n",
      " [2.22491220e-01]\n",
      " [5.71611404e-01]\n",
      " [8.24655473e-01]\n",
      " [9.99949932e-01]\n",
      " [8.48739266e-01]\n",
      " [9.56228554e-01]\n",
      " [3.86395216e-01]\n",
      " [1.15634941e-06]\n",
      " [3.48380813e-03]\n",
      " [3.81581217e-01]\n",
      " [4.65142146e-14]\n",
      " [6.63236715e-03]\n",
      " [4.58983798e-03]\n",
      " [4.25771316e-19]\n",
      " [4.99885827e-01]\n",
      " [1.30697164e-09]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.load_model(\"/content/drive/My Drive/DeepFakeFiles/DeepFakeModel.h5\")\n",
    "pred = model.predict(test,steps=100,verbose=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zR27Y1asMO09"
   },
   "outputs": [],
   "source": [
    "np.save(\"/content/drive/My Drive/DeepFakeFiles/results.npy\",pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DeepFakeChallenge.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
